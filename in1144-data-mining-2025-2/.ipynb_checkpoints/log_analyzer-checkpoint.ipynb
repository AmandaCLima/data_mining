{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8893a0f9-296e-45a9-924d-5c7df772bfa8",
   "metadata": {},
   "source": [
    "## Instalar requisitos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4466e5f2-d3b8-4317-ba11-6332c5ddfae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install \"betterproto[compiler]\" protobuf\n",
    "%pip install matplotlib\n",
    "%pip install scipy\n",
    "%pip install pyQt5\n",
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "%matplotlib qt      \n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aec73e-87af-48c1-97cf-5bb77b569815",
   "metadata": {},
   "source": [
    "## Pyproto generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2393a72e-c4ce-46ed-9558-0913d67b069e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrappers em: C:\\Users\\victo\\Documents\\in1144-data-mining-2025-2\\.protoc_plugins\n",
      "CMD: C:\\ProgramData\\chocolatey\\bin\\protoc.EXE --plugin=protoc-gen-python_betterproto=C:\\Users\\victo\\Documents\\in1144-data-mining-2025-2\\.protoc_plugins\\protoc-gen-python_betterproto.cmd -I C:\\Users\\victo\\Documents\\in1144-data-mining-2025-2\\libs\\protobufs\\include\\protobufs\\pb\\proto --python_betterproto_out=C:\\Users\\victo\\Documents\\in1144-data-mining-2025-2\\proto\\generated rc_log.proto\n",
      "returncode: 0\n",
      "STDOUT:\n",
      " \n",
      "STDERR:\n",
      " Writing RCLog.py\n",
      "Writing RoboCupSSL.py\n",
      "Writing __init__.py\n",
      "\n",
      "‚úÖ Sucesso!\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "plugin_dir = Path.cwd() / \".protoc_plugins\"\n",
    "plugin_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# para cobrir ambas as formas (h√≠fen e underscore)\n",
    "bat = f'@echo off\\r\\n\"{sys.executable}\" -m betterproto.plugin %*\\r\\n'\n",
    "(plugin_dir / \"protoc-gen-python_betterproto.cmd\").write_text(bat, encoding=\"utf-8\")\n",
    "(plugin_dir / \"protoc-gen-python-betterproto.cmd\").write_text(bat, encoding=\"utf-8\")\n",
    "\n",
    "# injeta pasta no PATH do processo do kernel\n",
    "os.environ[\"PATH\"] = str(plugin_dir) + os.pathsep + os.environ[\"PATH\"]\n",
    "\n",
    "print(\"Wrappers em:\", plugin_dir)\n",
    "\n",
    "from utils.auto_generate_proto import generate_proto_classes\n",
    "\n",
    "generate_proto_classes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26faa6a1-36ab-403e-9d90-6eccf88252a0",
   "metadata": {},
   "source": [
    "## Base includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f40200-5246-4f1a-919d-ed6a4fde45a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_select.data_filter_operator import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import OUTPUT_DIR, data_frame_to_csv, LogFields, gel_2d_length_in_column\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce8f940-5c82-49b7-85a9-d382529f1f90",
   "metadata": {},
   "source": [
    "## Path to Log File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6efdf8ba-f1c4-45a3-8110-78233e2c84aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX_PATH = '../logs/'\n",
    "LOG_FILE = 'group_phase_tigers_robocin.log.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc949f26-2591-4d45-863f-af9e737d302d",
   "metadata": {},
   "source": [
    "## Load Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7fbb2a-8c38-4f08-a077-7ea4450a9538",
   "metadata": {},
   "outputs": [],
   "source": [
    "selects = [LogFields.PROCESSED_FRAME, LogFields.REFEREE, LogFields.TELEMETRY, LogFields.ROBOTS_COMMAND]\n",
    "\n",
    "data_list = load_select_modules(PREFIX_PATH+LOG_FILE, selects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86bb49-e786-44fb-9475-e110b3c1e5cd",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b87cd0-3d32-4306-8d2c-e242e1cbeed4",
   "metadata": {},
   "source": [
    "### Robot Analysis\n",
    "Description ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287e626-81ef-421b-8f9f-6e0069f5dfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_robot = raw_frame_extract_robot_data_frame(data_list, True, 2)\n",
    "robot = processed_frame_extract_robot_data_frame(data_list, True, 6)\n",
    "\n",
    "print(len(robot), len(raw_robot))\n",
    "\n",
    "robot['timestamp'] = robot['timestamp'].apply(lambda x: float(x))\n",
    "raw_robot['timestamp'] = raw_robot['timestamp'].apply(lambda x: float(x))\n",
    "robot = robot[robot['timestamp'] > 1]\n",
    "\n",
    "timeref = min(robot['timestamp'].values[0], raw_robot['timestamp'].values[0])\n",
    "\n",
    "robot['timestamp'] = (robot['timestamp'] - timeref).apply(lambda x: float(x)%1e13/1e9)\n",
    "raw_robot['timestamp'] = (raw_robot['timestamp'] - timeref).apply(lambda x: float(x)%1e13/1e9)\n",
    "\n",
    "plt.plot(robot['timestamp'].values,robot['position_w'].values, label='processed')\n",
    "plt.plot(raw_robot['timestamp'].values,  raw_robot['position_w'].values, label='raw')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a095aa7e",
   "metadata": {},
   "source": [
    "# Inspecionar `.log.gz` e mostrar colunas\n",
    "\n",
    "Este notebook tenta **detectar automaticamente** o formato do seu arquivo comprimido (`.log.gz`) e exibir as **colunas** que ele cont√©m.\n",
    "\n",
    "**O que ele faz:**\n",
    "1. L√™ algumas linhas de amostra descompactando o arquivo.\n",
    "2. Detecta se o formato parece **JSON Lines (NDJSON)** ou **CSV/TSV/pipe**.\n",
    "3. Se for JSON Lines, usa `pandas.read_json(..., lines=True)`; se for CSV-like, tenta inferir o delimitador.\n",
    "4. Exibe: colunas, tipos (`dtypes`) e primeiras linhas (`head()`).\n",
    "\n",
    "**Requisitos**: `pandas`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a988f7cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo configurado: C:\\Users\\victo\\Documents\\in1144-data-mining-2025-2\\logs\\group_phase_tigers_robocin.log.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# üëâ 1) Ajuste aqui o caminho do seu arquivo .log.gz\n",
    "file_path = r\"C:\\Users\\victo\\Documents\\in1144-data-mining-2025-2\\logs\\group_phase_tigers_robocin.log.gz\"  # Exemplo no Windows\n",
    "# file_path = \"/caminho/para/seu_arquivo.log.gz\"     # Exemplo no Linux/Mac\n",
    "\n",
    "print(\"Arquivo configurado:\", file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2445e73e",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'\\n#')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadGzipFile\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    104\u001b[39m                 \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e3:\n\u001b[32m    105\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFalha ao ler como texto delimitado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me3\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m df, meta = \u001b[43mquick_preview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFormato detectado:\u001b[39m\u001b[33m\"\u001b[39m, meta[\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDelimitador detectado:\u001b[39m\u001b[33m\"\u001b[39m, meta[\u001b[33m\"\u001b[39m\u001b[33mdelimiter\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mquick_preview\u001b[39m\u001b[34m(path, nrows)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mquick_preview\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, nrows: \u001b[38;5;28mint\u001b[39m = \u001b[32m1000\u001b[39m):\n\u001b[32m     50\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Tenta carregar um peda√ßo do arquivo como JSON Lines ou CSV-like e retorna (df, info_dict).\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     sample = \u001b[43mread_sample_lines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lines\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sample:\n\u001b[32m     53\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mN√£o foi poss√≠vel ler amostras do arquivo (vazio?).\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mread_sample_lines\u001b[39m\u001b[34m(path, max_lines)\u001b[39m\n\u001b[32m      6\u001b[39m lines = []\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m gzip.open(path, mode=\u001b[33m\"\u001b[39m\u001b[33mrt\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m, errors=\u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m, newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_lines\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mbreak\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python314\\Lib\\gzip.py:360\u001b[39m, in \u001b[36mGzipFile.read1\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size < \u001b[32m0\u001b[39m:\n\u001b[32m    359\u001b[39m     size = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python314\\Lib\\compression\\_common\\_streams.py:68\u001b[39m, in \u001b[36mDecompressReader.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view.cast(\u001b[33m\"\u001b[39m\u001b[33mB\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] = data\n\u001b[32m     70\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python314\\Lib\\gzip.py:570\u001b[39m, in \u001b[36m_GzipReader.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    566\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._new_member:\n\u001b[32m    567\u001b[39m     \u001b[38;5;66;03m# If the _new_member flag is set, we have to\u001b[39;00m\n\u001b[32m    568\u001b[39m     \u001b[38;5;66;03m# jump to the next member, if there is one.\u001b[39;00m\n\u001b[32m    569\u001b[39m     \u001b[38;5;28mself\u001b[39m._init_read()\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_gzip_header\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    571\u001b[39m         \u001b[38;5;28mself\u001b[39m._size = \u001b[38;5;28mself\u001b[39m._pos\n\u001b[32m    572\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python314\\Lib\\gzip.py:539\u001b[39m, in \u001b[36m_GzipReader._read_gzip_header\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_gzip_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     last_mtime = \u001b[43m_read_gzip_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m last_mtime \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    541\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python314\\Lib\\gzip.py:499\u001b[39m, in \u001b[36m_read_gzip_header\u001b[39m\u001b[34m(fp)\u001b[39m\n\u001b[32m    496\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic != \u001b[33mb\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\037\u001b[39;00m\u001b[38;5;130;01m\\213\u001b[39;00m\u001b[33m'\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m499\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m BadGzipFile(\u001b[33m'\u001b[39m\u001b[33mNot a gzipped file (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m % magic)\n\u001b[32m    501\u001b[39m (method, flag, last_mtime) = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m<BBIxx\u001b[39m\u001b[33m\"\u001b[39m, _read_exact(fp, \u001b[32m8\u001b[39m))\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m method != \u001b[32m8\u001b[39m:\n",
      "\u001b[31mBadGzipFile\u001b[39m: Not a gzipped file (b'\\n#')"
     ]
    }
   ],
   "source": [
    "\n",
    "import gzip, io, csv, json, re\n",
    "import pandas as pd\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "def read_sample_lines(path: str, max_lines: int = 30) -> List[str]:\n",
    "    lines = []\n",
    "    with gzip.open(path, mode=\"rt\", encoding=\"utf-8\", errors=\"replace\", newline=\"\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= max_lines:\n",
    "                break\n",
    "            # guarda apenas linhas n√£o vazias (mas mant√©m linhas curtas)\n",
    "            if line.strip() != \"\":\n",
    "                lines.append(line.rstrip(\"\\n\"))\n",
    "    return lines\n",
    "\n",
    "def looks_like_json_line(s: str) -> bool:\n",
    "    s = s.strip()\n",
    "    # heur√≠stica bem simples: come√ßa com { ou [ e termina plausivelmente\n",
    "    return (s.startswith(\"{\") and (\"}\" in s)) or (s.startswith(\"[\") and (\"]\" in s))\n",
    "\n",
    "def detect_delimiter(sample_lines: List[str]) -> Optional[str]:\n",
    "    text = \"\\n\".join(sample_lines[:20])\n",
    "    # 1) tenta csv.Sniffer\n",
    "    try:\n",
    "        dialect = csv.Sniffer().sniff(text, delimiters=[',',';','\\t','|',':'])\n",
    "        return dialect.delimiter\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 2) fallback: escolher o delimitador que mais aparece de forma consistente\n",
    "    candidates = [',',';','\\t','|',':']\n",
    "    best = None\n",
    "    best_score = -1\n",
    "    for delim in candidates:\n",
    "        counts = [len(l.split(delim)) for l in sample_lines if delim in l]\n",
    "        if counts:\n",
    "            # pontua pela mediana do n√∫mero de colunas (quanto maior e consistente, melhor)\n",
    "            import statistics as stats\n",
    "            try:\n",
    "                med = stats.median(counts)\n",
    "                var = stats.pvariance(counts) if len(counts) > 1 else 0\n",
    "                score = med - 0.1*var\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best = delim\n",
    "            except Exception:\n",
    "                pass\n",
    "    return best\n",
    "\n",
    "def quick_preview(path: str, nrows: int = 1000):\n",
    "    \"\"\"Tenta carregar um peda√ßo do arquivo como JSON Lines ou CSV-like e retorna (df, info_dict).\"\"\"\n",
    "    sample = read_sample_lines(path, max_lines=50)\n",
    "    if not sample:\n",
    "        raise RuntimeError(\"N√£o foi poss√≠vel ler amostras do arquivo (vazio?).\")\n",
    "\n",
    "    # Decide formato\n",
    "    is_jsonl = False\n",
    "    for s in sample:\n",
    "        if looks_like_json_line(s):\n",
    "            is_jsonl = True\n",
    "            break\n",
    "\n",
    "    info = {\"format\": \"jsonl\" if is_jsonl else \"csv-like\", \"delimiter\": None, \"header_inferido\": None}\n",
    "\n",
    "    if is_jsonl:\n",
    "        try:\n",
    "            df = pd.read_json(path, lines=True, compression=\"gzip\", dtype=False)\n",
    "            # se houver colunas com dict/list, tenta um flatten superficial\n",
    "            if any(df.applymap(lambda x: isinstance(x, (dict, list))).any(axis=None) for _ in [0]):\n",
    "                # normaliza apenas uma camada\n",
    "                records = df.to_dict(orient=\"records\")\n",
    "                df = pd.json_normalize(records, max_level=1)\n",
    "            info[\"header_inferido\"] = True  # JSON j√° vem com chaves como colunas\n",
    "            return df, info\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Falha ao ler como JSON Lines: {e}\")\n",
    "    else:\n",
    "        # CSV-like\n",
    "        delim = detect_delimiter(sample)\n",
    "        info[\"delimiter\"] = repr(delim) if delim is not None else None\n",
    "        # Primeiro, tenta inferir header automaticamente\n",
    "        try:\n",
    "            df_try = pd.read_csv(path, compression=\"gzip\", sep=None, engine=\"python\", nrows=nrows)\n",
    "            info[\"header_inferido\"] = True  # se deu certo, o pandas j√° inferiu algo\n",
    "            return df_try, info\n",
    "        except Exception:\n",
    "            # Segundo, tenta com delimitador detectado\n",
    "            if delim is not None:\n",
    "                try:\n",
    "                    df_try = pd.read_csv(path, compression=\"gzip\", sep=delim, engine=\"python\", nrows=nrows)\n",
    "                    # Heur√≠stica: se as colunas forem 0..N-1, pode n√£o haver cabe√ßalho\n",
    "                    if all(isinstance(c, int) for c in df_try.columns):\n",
    "                        info[\"header_inferido\"] = False\n",
    "                    else:\n",
    "                        info[\"header_inferido\"] = True\n",
    "                    return df_try, info\n",
    "                except Exception as e2:\n",
    "                    raise RuntimeError(f\"Falha ao ler como CSV com delimitador {delim!r}: {e2}\")\n",
    "            else:\n",
    "                # Por fim, tenta espa√ßo em branco como separador vari√°vel\n",
    "                try:\n",
    "                    df_try = pd.read_csv(path, compression=\"gzip\", delim_whitespace=True, engine=\"python\", nrows=nrows, header=None)\n",
    "                    info[\"header_inferido\"] = False\n",
    "                    return df_try, info\n",
    "                except Exception as e3:\n",
    "                    raise RuntimeError(f\"Falha ao ler como texto delimitado: {e3}\")\n",
    "\n",
    "df, meta = quick_preview(file_path, nrows=2000)\n",
    "print(\"Formato detectado:\", meta[\"format\"])\n",
    "print(\"Delimitador detectado:\", meta[\"delimiter\"])\n",
    "print(\"Cabe√ßalho inferido:\", meta[\"header_inferido\"])\n",
    "print(\"\\nTotal de colunas detectadas:\", len(df.columns))\n",
    "print(\"Colunas:\", list(map(str, df.columns)))\n",
    "\n",
    "display(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751911ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Opcional) Se N√ÉO houver cabe√ßalho e voc√™ souber os nomes das colunas,\n",
    "# defina-os abaixo e recarregue um peda√ßo para confirmar:\n",
    "# Exemplo:\n",
    "# known_cols = [\"ts\",\"level\",\"msg\",\"thread\",\"extra\"]\n",
    "# df_named = pd.read_csv(file_path, compression=\"gzip\", sep=\",\", names=known_cols, header=None, nrows=1000)\n",
    "# display(df_named.head())\n",
    "known_cols = None\n",
    "if known_cols:\n",
    "    print(\"Usando nomes fornecidos:\", known_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045d75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Opcional) Dicion√°rio de tipos para economizar mem√≥ria ou corrigir infer√™ncia de tipo\n",
    "# Exemplo: dtypes = {\"ts\":\"float64\", \"level\":\"category\"}\n",
    "dtypes = {}\n",
    "\n",
    "print(\"Tipos inferidos pelo pandas:\")\n",
    "display(df.dtypes.to_frame(\"dtype\"))\n",
    "\n",
    "# Mostra uma amostra aleat√≥ria para verificar a consist√™ncia visual\n",
    "print(\"\\nAmostra aleat√≥ria:\")\n",
    "display(df.sample(min(len(df), 10), random_state=42))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84712034",
   "metadata": {},
   "source": [
    "## Dicas\n",
    "- Se o seu log for JSON Lines (um JSON por linha), o m√©todo acima j√° mostra as chaves como colunas.\n",
    "- Se o arquivo for CSV/TSV, mas **sem cabe√ßalho**, voc√™ ver√° colunas num√©ricas (0, 1, 2, ...). Use a c√©lula de *nomes conhecidos* para definir os nomes.\n",
    "- Se houver campos complexos (listas/dicion√°rios), considere usar `pd.json_normalize` para *flatten* adicional.\n",
    "- Para carregar o arquivo completo, remova o par√¢metro `nrows` (cuidado com a RAM).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
